{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List, Dict, Any\n",
    "from constants import *\n",
    "\n",
    "\n",
    "\n",
    "# 90 of the test segments are genuine (i.e., benign) and 10 segments are entered bya masquerader (randomly sorted)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T15:26:27.593458622Z",
     "start_time": "2023-04-29T15:26:27.558957345Z"
    }
   },
   "outputs": [],
   "source": [
    "#   load answer for classifcation\n",
    "gt_df = pd.read_csv(\"challengeToFill.csv\", index_col=0)\n",
    "gt_df.T[TRAIN_SEGMENT_COUNT:]\n",
    "\n",
    "\n",
    "\n",
    "dev_set_df = gt_df.T.iloc[TRAIN_SEGMENT_COUNT:, :DEV_USERS_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_user_results(pred_series: pd.Series, true_series: pd.Series):\n",
    "    ''' evaluate the classification result of a single user '''\n",
    "    assert len(pred_series) == len(true_series)\n",
    "    assert pred_series.name == true_series.name\n",
    "\n",
    "    equal_series = pred_series == true_series\n",
    "    return equal_series.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T14:19:03.677122723Z",
     "start_time": "2023-04-29T14:19:03.668204554Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_list_to_df(user_id: str, user_data_list: List[str]):\n",
    "    df_user = pd.DataFrame({\n",
    "        \"cmd\": user_data_list\n",
    "    })\n",
    "    df_user[\"user\"] = user_id\n",
    "    df_user[\"split\"] = \"train\"\n",
    "    df_user[\"segment_id\"] = np.repeat(range(0, int(len(user_data_list) / SEGMENT_LEN)), SEGMENT_LEN)\n",
    "    df_user[\"cmd\"] = df_user[\"cmd\"].astype(\"category\")\n",
    "    return df_user\n",
    "\n",
    "\n",
    "def load_user_data(user_id: str, file_path: os.PathLike) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    with open(file_path, \"r\") as fp:\n",
    "        user_data = fp.readlines()\n",
    "        user_data = [s.strip() for s in user_data]\n",
    "\n",
    "    # get training data:\n",
    "    train_user_data = user_data[:TRAIN_HEADER_COUNT]\n",
    "    test_user_data = user_data[TRAIN_HEADER_COUNT:]\n",
    "\n",
    "    # convert to dataframes\n",
    "    train_segments = user_list_to_df(user_id, train_user_data)\n",
    "    test_segments = user_list_to_df(user_id, test_user_data)\n",
    "\n",
    "    return train_segments, test_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T14:19:03.677431798Z",
     "start_time": "2023-04-29T14:19:03.668482120Z"
    }
   },
   "outputs": [],
   "source": [
    "''' load all user data '''\n",
    "\n",
    "user_id = \"User5\"\n",
    "user_file_path = os.path.join(\"data\", user_id)\n",
    "\n",
    "df_user0_train, df_user0_test = load_user_data(user_id, user_file_path)\n",
    "anomaly_ground_truth = gt_df.T[user_id].values.astype(int)[TRAIN_SEGMENT_COUNT:]# test set only\n",
    "\n",
    "''' all commands '''\n",
    "\n",
    "user_cmd_set_train = set(df_user0_train[\"cmd\"].unique())\n",
    "user_cmd_set_test = set(df_user0_test[\"cmd\"].unique())\n",
    "\n",
    "user_cmd_set = user_cmd_set_test.union(user_cmd_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T14:19:03.678292689Z",
     "start_time": "2023-04-29T14:19:03.668758714Z"
    }
   },
   "outputs": [],
   "source": [
    "# cmds that appear in the test and not in train\n",
    "user_cmd_set_not_in_train = user_cmd_set_test.difference(user_cmd_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T14:19:03.678587368Z",
     "start_time": "2023-04-29T14:19:03.669071366Z"
    }
   },
   "outputs": [],
   "source": [
    "cmd_map_code = {c: i for i, c in enumerate(user_cmd_set)}\n",
    "MAP_CODE_LEN = len(cmd_map_code)\n",
    "\n",
    "df_user0_train[\"cmd_code\"] = df_user0_train[\"cmd\"].map(cmd_map_code).astype(int)\n",
    "df_user0_test[\"cmd_code\"] = df_user0_test[\"cmd\"].map(cmd_map_code).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T14:19:03.678842672Z",
     "start_time": "2023-04-29T14:19:03.669475733Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T14:19:03.913351387Z",
     "start_time": "2023-04-29T14:19:03.676969262Z"
    }
   },
   "outputs": [],
   "source": [
    "from features.segment import build_segment_features\n",
    "\n",
    "\n",
    "train_segment_features_list = []\n",
    "test_segment_features_list = []\n",
    "\n",
    "for i in range(TRAIN_SEGMENT_COUNT):\n",
    "    train_segment_features_list.append(build_segment_features(df_user0_train, user_cmd_set_not_in_train ,i))\n",
    "\n",
    "for i in range(TEST_SEGMENT_COUNT):\n",
    "    test_segment_features_list.append(build_segment_features(df_user0_test, user_cmd_set_not_in_train ,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T14:19:03.958913502Z",
     "start_time": "2023-04-29T14:19:03.915076817Z"
    }
   },
   "outputs": [],
   "source": [
    "segment_df_train = pd.DataFrame.from_records(train_segment_features_list)\n",
    "segment_df_test = pd.DataFrame.from_records(test_segment_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize_commands\n",
    "segment_df_train[\"cmd_most_used_code\"] = pd.Categorical(segment_df_train[\"cmd_most_used\"].astype(\"category\"),\n",
    "                                                        categories=user_cmd_set)\n",
    "segment_df_train[\"first_cmd_code\"] = pd.Categorical(segment_df_train[\"first_cmd\"], categories=user_cmd_set)\n",
    "segment_df_train[\"last_cmd_code\"] = pd.Categorical(segment_df_train[\"last_cmd\"], categories=user_cmd_set)\n",
    "\n",
    "segment_df_test[\"cmd_most_used_code\"] = pd.Categorical(segment_df_test[\"cmd_most_used\"], categories=user_cmd_set)\n",
    "segment_df_test[\"first_cmd_code\"] = pd.Categorical(segment_df_test[\"first_cmd\"], categories=user_cmd_set)\n",
    "segment_df_test[\"last_cmd_code\"] = pd.Categorical(segment_df_test[\"last_cmd\"], categories=user_cmd_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "corr = pd.concat([pd.DataFrame({\"anomaly\": anomaly_ground_truth}), segment_df_test.iloc[:, 3:-3]], axis=1).corr()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "                            anomaly  unique_cmds  longest_same_cmd_sequence   \nanomaly                    1.000000    -0.056223                   0.140882  \\\nunique_cmds               -0.056223     1.000000                  -0.158038   \nlongest_same_cmd_sequence  0.140882    -0.158038                   1.000000   \ncmd_not_in_train_count    -0.386507     0.146715                   0.175519   \nsingle_chars_cmd_count          NaN          NaN                        NaN   \ntwo_chars_cmds_count            NaN          NaN                        NaN   \nthree_chars_cmds_count          NaN          NaN                        NaN   \nfour_chars_cmds_count           NaN          NaN                        NaN   \nends_with_dot_cmds_count        NaN          NaN                        NaN   \nhas_dot_in_middle               NaN          NaN                        NaN   \n\n                           cmd_not_in_train_count  single_chars_cmd_count   \nanomaly                                 -0.386507                     NaN  \\\nunique_cmds                              0.146715                     NaN   \nlongest_same_cmd_sequence                0.175519                     NaN   \ncmd_not_in_train_count                   1.000000                     NaN   \nsingle_chars_cmd_count                        NaN                     NaN   \ntwo_chars_cmds_count                          NaN                     NaN   \nthree_chars_cmds_count                        NaN                     NaN   \nfour_chars_cmds_count                         NaN                     NaN   \nends_with_dot_cmds_count                      NaN                     NaN   \nhas_dot_in_middle                             NaN                     NaN   \n\n                           two_chars_cmds_count  three_chars_cmds_count   \nanomaly                                     NaN                     NaN  \\\nunique_cmds                                 NaN                     NaN   \nlongest_same_cmd_sequence                   NaN                     NaN   \ncmd_not_in_train_count                      NaN                     NaN   \nsingle_chars_cmd_count                      NaN                     NaN   \ntwo_chars_cmds_count                        NaN                     NaN   \nthree_chars_cmds_count                      NaN                     NaN   \nfour_chars_cmds_count                       NaN                     NaN   \nends_with_dot_cmds_count                    NaN                     NaN   \nhas_dot_in_middle                           NaN                     NaN   \n\n                           four_chars_cmds_count  ends_with_dot_cmds_count   \nanomaly                                      NaN                       NaN  \\\nunique_cmds                                  NaN                       NaN   \nlongest_same_cmd_sequence                    NaN                       NaN   \ncmd_not_in_train_count                       NaN                       NaN   \nsingle_chars_cmd_count                       NaN                       NaN   \ntwo_chars_cmds_count                         NaN                       NaN   \nthree_chars_cmds_count                       NaN                       NaN   \nfour_chars_cmds_count                        NaN                       NaN   \nends_with_dot_cmds_count                     NaN                       NaN   \nhas_dot_in_middle                            NaN                       NaN   \n\n                           has_dot_in_middle  \nanomaly                                  NaN  \nunique_cmds                              NaN  \nlongest_same_cmd_sequence                NaN  \ncmd_not_in_train_count                   NaN  \nsingle_chars_cmd_count                   NaN  \ntwo_chars_cmds_count                     NaN  \nthree_chars_cmds_count                   NaN  \nfour_chars_cmds_count                    NaN  \nends_with_dot_cmds_count                 NaN  \nhas_dot_in_middle                        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>anomaly</th>\n      <th>unique_cmds</th>\n      <th>longest_same_cmd_sequence</th>\n      <th>cmd_not_in_train_count</th>\n      <th>single_chars_cmd_count</th>\n      <th>two_chars_cmds_count</th>\n      <th>three_chars_cmds_count</th>\n      <th>four_chars_cmds_count</th>\n      <th>ends_with_dot_cmds_count</th>\n      <th>has_dot_in_middle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anomaly</th>\n      <td>1.000000</td>\n      <td>-0.056223</td>\n      <td>0.140882</td>\n      <td>-0.386507</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>unique_cmds</th>\n      <td>-0.056223</td>\n      <td>1.000000</td>\n      <td>-0.158038</td>\n      <td>0.146715</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>longest_same_cmd_sequence</th>\n      <td>0.140882</td>\n      <td>-0.158038</td>\n      <td>1.000000</td>\n      <td>0.175519</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>cmd_not_in_train_count</th>\n      <td>-0.386507</td>\n      <td>0.146715</td>\n      <td>0.175519</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>single_chars_cmd_count</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>two_chars_cmds_count</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>three_chars_cmds_count</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>four_chars_cmds_count</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>ends_with_dot_cmds_count</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>has_dot_in_middle</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-29T14:19:03.966805256Z",
     "start_time": "2023-04-29T14:19:03.959297740Z"
    }
   },
   "outputs": [],
   "source": [
    "train_feature_df = pd.get_dummies(segment_df_train, columns=[\"cmd_most_used_code\", \"first_cmd_code\", \"last_cmd_code\"],\n",
    "                                  prefix=\"is\", dtype=float)\n",
    "dev_feature_df = pd.get_dummies(segment_df_test, columns=[\"cmd_most_used_code\", \"first_cmd_code\", \"last_cmd_code\"],\n",
    "                                prefix=\"is\", dtype=float)\n",
    "\n",
    "\n",
    "# remove non numeric features\n",
    "train_feature_df = train_feature_df.iloc[:, 3:]\n",
    "dev_feature_df = dev_feature_df.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' first outlier detection algo '''\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "anomaly_ground_truth = gt_df.T[user_id].values.astype(int)[TRAIN_SEGMENT_COUNT:]# test set only\n",
    "anomaly_ground_truth = np.array([1 if x == 0 else -1 for x in anomaly_ground_truth])\n",
    "\n",
    "detector = LocalOutlierFactor(novelty=True, leaf_size=5)\n",
    "\n",
    "detector.fit(train_feature_df)\n",
    "\n",
    "predicted_anomalies = detector.predict(dev_feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "reducer = UMAP()\n",
    "S_train_low_dim = reducer.fit_transform(train_feature_df)\n",
    "S_dev_low_dim = reducer.transform(dev_feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "detector = LocalOutlierFactor(novelty=True)\n",
    "\n",
    "detector.fit(S_train_low_dim)\n",
    "\n",
    "low_dim_predicted_anomalies = detector.predict(S_dev_low_dim)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all bengin score\n",
      "{'detection_score': 0.0, 'precison': '1.000', 'recall': '0.900'}\n",
      "all fraud score\n",
      "{'detection_score': 1.0, 'precison': '0.000', 'recall': '0.000'}\n",
      "high dim\n",
      "{'detection_score': 0.0, 'precison': '0.844', 'recall': '0.884'}\n",
      "low dim\n",
      "{'detection_score': 0.0, 'precison': '1.000', 'recall': '0.900'}\n"
     ]
    }
   ],
   "source": [
    "from eval.metrics import detection_metrics\n",
    "\n",
    "\n",
    "print(\"all bengin score\")\n",
    "high_dim_score = detection_metrics(np.ones_like(anomaly_ground_truth), anomaly_ground_truth)\n",
    "print(high_dim_score)\n",
    "\n",
    "\n",
    "print(\"all fraud score\")\n",
    "high_dim_score = detection_metrics(-1 * np.ones_like(anomaly_ground_truth), anomaly_ground_truth)\n",
    "print(high_dim_score)\n",
    "\n",
    "print(\"high dim\")\n",
    "high_dim_score = detection_metrics(predicted_anomalies, anomaly_ground_truth)\n",
    "print(high_dim_score)\n",
    "\n",
    "print(\"low dim\")\n",
    "low_dim_score = detection_metrics(low_dim_predicted_anomalies, anomaly_ground_truth)\n",
    "print(low_dim_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1,  1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,\n        1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_dim_predicted_anomalies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "\n",
    "viz_df_train = pd.DataFrame({\n",
    "    \"x\": S_train_low_dim[:, 0],\n",
    "    \"y\": S_train_low_dim[:, 1],\n",
    "    \"user\": TRAIN_SEGMENT_COUNT * [user_id],\n",
    "    \"set\": TRAIN_SEGMENT_COUNT * [\"train\"]\n",
    "})\n",
    "\n",
    "viz_df_test = pd.DataFrame({\n",
    "    \"x\": S_dev_low_dim[:, 0],\n",
    "    \"y\": S_dev_low_dim[:, 1],\n",
    "    \"user\": TEST_SEGMENT_COUNT * [user_id],\n",
    "    \"set\": TEST_SEGMENT_COUNT * [\"test\"]\n",
    "})\n",
    "\n",
    "\n",
    "viz_df = pd.concat([viz_df_train, viz_df_test], axis=0)\n",
    "viz_df[\"anomaly\"] = gt_df.T[user_id].values\n",
    "viz_df[\"anomaly\"] = viz_df[\"anomaly\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import plotly.io as pio\n",
    "# pio.renderers.default='notebook'\n",
    "#\n",
    "px.scatter(viz_df, x=\"x\", y=\"y\", color=\"anomaly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
