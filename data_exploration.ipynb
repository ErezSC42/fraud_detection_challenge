{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T19:09:02.946970206Z",
     "start_time": "2023-05-21T19:09:02.946577668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Tuple, List, Dict, Any\n",
    "from constants import *\n",
    "from features.user import User\n",
    "\n",
    "\n",
    "# 90 of the test segments are genuine (i.e., benign) and 10 segments are entered bya masquerader (randomly sorted)."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T19:19:18.256685979Z",
     "start_time": "2023-05-21T19:19:18.198579211Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T19:09:03.393662793Z",
     "start_time": "2023-05-21T19:09:03.375968867Z"
    }
   },
   "outputs": [],
   "source": [
    "#   load answer for classifcation\n",
    "gt_df = pd.read_csv(\"challengeToFill.csv\", index_col=0).T[TRAIN_SEGMENT_COUNT:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dev_set_df = gt_df.T.iloc[TRAIN_SEGMENT_COUNT:, :DEV_USERS_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:01<00:00, 18.12s/it]\n"
     ]
    }
   ],
   "source": [
    "user_list = [f\"User{i}\" for i in range(10)]\n",
    "submission_user_list = [f\"User{i}\" for i in range(10, 40)]\n",
    "data_path = [f\"data/{uid}\" for uid in user_list]\n",
    "submission_data_path = [f\"data/{uid}\" for uid in submission_user_list]\n",
    "\n",
    "user_data = {}\n",
    "\n",
    "for user_id, user_data_path in tqdm.tqdm(zip(user_list, data_path), total=len(user_list)):\n",
    "    #   load user data\n",
    "    user_data[user_id] = User(user_id, user_data_path, gt_df[user_id])\n",
    "\n",
    "    # create segment features\n",
    "    user_data[user_id].build_segment_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_test_segments = [user_data[user_id].segment_df_test.select_dtypes(\"number\") for user_id in user_list]\n",
    "all_test_segments_gt = [user_data[user_id].user_anomaly_gt for user_id in user_list]\n",
    "\n",
    "all_test_segments = pd.concat(all_test_segments).reset_index(drop=True)\n",
    "all_test_segments[\"anomaly\"] = pd.concat(all_test_segments_gt).reset_index(drop=True)\n",
    "\n",
    "all_test_segments[\"noise\"] = np.random.rand(len(all_test_segments))\n",
    "\n",
    "\n",
    "corr = all_test_segments.corr()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T19:09:20.505191847Z",
     "start_time": "2023-05-21T19:09:19.412259797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T19:09:20.518417158Z",
     "start_time": "2023-05-21T19:09:20.505729147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "#   get feature correlations to anomaly\n",
    "\n",
    "TOP_K = 50\n",
    "\n",
    "corr[\"anomaly\"].sort_values(ascending=False)\n",
    "\n",
    "top_k_features = corr[\"anomaly\"].sort_values(ascending=False)[1:TOP_K].index.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T19:24:32.124200413Z",
     "start_time": "2023-05-21T19:24:32.110429130Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "['cmds_not_in_train',\n 'not_in_train_has_all_lowercase_cmds',\n 'not_in_train_has_mail_cmds',\n 'not_in_train_has_uppercase_cmds',\n 'not_in_train_three_chars_cmds',\n 'not_in_train_four_chars_cmds',\n 'not_in_train_has_numerics_cmds',\n 'not_in_train_has_dot_in_middle_cmds',\n 'not_in_train_two_chars_cmds',\n 'tfidf_mediamai',\n 'tfidf_maple',\n 'tfidf_sy',\n 'tfidf_sendmail',\n 'not_in_train_has_coding_cmds',\n 'not_in_train_single_chars_cmds',\n 'tfidf_tty',\n 'tfidf_magma',\n 'tfidf_sprog',\n 'tfidf_mapletty',\n 'tfidf_tput',\n 'not_in_train_starts_with_dotfile_cmds',\n 'not_in_train_has_ssh_cmds',\n 'has_ssh_cmds',\n 'has_uppercase_cmds',\n 'tfidf_detex',\n 'tfidf_xmaplev5',\n 'tfidf_tracy',\n 'tfidf_pine',\n 'not_in_train_has_navigation_cmds',\n 'tfidf_archie',\n 'tfidf_spell',\n 'tfidf_mp',\n 'tfidf_m4',\n 'has_dot_in_middle_cmds',\n 'tfidf_lks',\n 'tfidf_ds_ar',\n 'tfidf_xbiff',\n 'tfidf_resize',\n 'tfidf_sizup',\n 'tfidf_whois',\n 'tfidf_reducyr',\n 'tfidf_dviselec',\n 'tfidf_arch',\n 'tfidf_exe',\n 'tfidf_less',\n 'has_mail_cmds',\n 'tfidf_time',\n 'tfidf_tset',\n 'tfidf_mail']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T19:16:21.252118396Z",
     "start_time": "2023-05-21T19:16:21.214682787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# fig = px.imshow(corr)\n",
    "# fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [07:59<31:56, 239.62s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLocalOutlierFactor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 27\u001B[0m\n\u001B[1;32m     22\u001B[0m X_test \u001B[38;5;241m=\u001B[39m user_data[user_id]\u001B[38;5;241m.\u001B[39mnormalized_features_test[top_k_features]\n\u001B[1;32m     24\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m''' feature selection '''\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m \u001B[43mdetector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m predicted_anomalies \u001B[38;5;241m=\u001B[39m detector\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m     31\u001B[0m user_scores_high_dim[user_id] \u001B[38;5;241m=\u001B[39m detection_metrics(predicted_anomalies, anomaly_ground_truth)\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/detection/pipeline.py:21\u001B[0m, in \u001B[0;36mDetectionPipeline.fit\u001B[0;34m(self, df_train)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     19\u001B[0m         df_train: pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures_train_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mget_dummies(df_train)\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures_train_df\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/venv/lib/python3.10/site-packages/sklearn/neighbors/_lof.py:278\u001B[0m, in \u001B[0;36mLocalOutlierFactor.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the local outlier factor detector from the training dataset.\u001B[39;00m\n\u001B[1;32m    261\u001B[0m \n\u001B[1;32m    262\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;124;03m    The fitted local outlier factor detector.\u001B[39;00m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m--> 278\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_samples_fit_\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_neighbors \u001B[38;5;241m>\u001B[39m n_samples:\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/venv/lib/python3.10/site-packages/sklearn/neighbors/_base.py:491\u001B[0m, in \u001B[0;36mNeighborsBase._fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    489\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    490\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001B[0;32m--> 491\u001B[0m         X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_algorithm_metric()\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/venv/lib/python3.10/site-packages/sklearn/base.py:565\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    563\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    564\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 565\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    566\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    567\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    915\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    916\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    917\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    918\u001B[0m         )\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 921\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    929\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    149\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m     )\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nLocalOutlierFactor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "''' first outlier detection algo '''\n",
    "from sklearn.decomposition import PCA\n",
    "from eval.metrics import detection_metrics\n",
    "from detection.pipeline import DetectionPipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "user_scores_high_dim = {}\n",
    "user_scores_low_dim = {}\n",
    "session_classification = {}\n",
    "\n",
    "for user_id in tqdm.tqdm(user_list):\n",
    "\n",
    "    anomaly_ground_truth = user_data[user_id].user_anomaly_gt.values.astype(int) # test set only\n",
    "    anomaly_ground_truth = np.array([1 if x == 0 else -1 for x in anomaly_ground_truth])\n",
    "\n",
    "    ''' high dim data '''\n",
    "\n",
    "    detector = DetectionPipeline()\n",
    "\n",
    "    X_train = user_data[user_id].normalized_features_train[top_k_features]\n",
    "    X_test = user_data[user_id].normalized_features_test[top_k_features]\n",
    "\n",
    "    ''' feature selection '''\n",
    "\n",
    "\n",
    "    detector.fit(X_train)\n",
    "    predicted_anomalies = detector.predict(X_test)\n",
    "\n",
    "\n",
    "    user_scores_high_dim[user_id] = detection_metrics(predicted_anomalies, anomaly_ground_truth)\n",
    "\n",
    "    session_classification[user_id] = [1 if x == -1 else 0 for x in predicted_anomalies]\n",
    "\n",
    "\n",
    "\n",
    "''' aggregate metrics '''\n",
    "\n",
    "\n",
    "overall_scores_high_dim = {}\n",
    "for score_type in [\"f1_score\", \"detection_score\" ,\"precision_score\", \"recall_score\"]:\n",
    "    overall_scores_high_dim[score_type] = np.mean([user_scores_high_dim[user_id][score_type] for user_id in user_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "{'f1_score': 0.8112999999999999,\n 'detection_score': 0.85,\n 'precision_score': 0.7112,\n 'recall_score': 0.9782}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {'f1_score': 0.8529,\n",
    "#  'detection_score': 0.66,\n",
    "#  'precision_score': 0.7899,\n",
    "#  'recall_score': 0.9563}\n",
    "\n",
    "overall_scores_high_dim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m detector \u001B[38;5;241m=\u001B[39m DetectionPipeline()\n\u001B[1;32m     20\u001B[0m detector\u001B[38;5;241m.\u001B[39mfit(submission_user_data[user_id]\u001B[38;5;241m.\u001B[39msegment_df_train)\n\u001B[0;32m---> 21\u001B[0m predicted_anomalies \u001B[38;5;241m=\u001B[39m \u001B[43mdetector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubmission_user_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43muser_id\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msegment_df_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m user_scores_high_dim[user_id] \u001B[38;5;241m=\u001B[39m detection_metrics(predicted_anomalies, anomaly_ground_truth)\n\u001B[1;32m     24\u001B[0m session_classification[user_id] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m predicted_anomalies]\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/detection/pipeline.py:25\u001B[0m, in \u001B[0;36mDetectionPipeline.predict\u001B[0;34m(self, df_test)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, df_test: pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures_test_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mget_dummies(df_test)\n\u001B[0;32m---> 25\u001B[0m     predicted_anomalies \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures_test_df\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predicted_anomalies\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/venv/lib/python3.10/site-packages/sklearn/neighbors/_lof.py:353\u001B[0m, in \u001B[0;36mLocalOutlierFactor.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;129m@available_if\u001B[39m(_check_novelty_predict)\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    334\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Predict the labels (1 inlier, -1 outlier) of X according to LOF.\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m    **Only available for novelty detection (when novelty is set to True).**\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    351\u001B[0m \u001B[38;5;124;03m        Returns -1 for anomalies/outliers and +1 for inliers.\u001B[39;00m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 353\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/venv/lib/python3.10/site-packages/sklearn/neighbors/_lof.py:375\u001B[0m, in \u001B[0;36mLocalOutlierFactor._predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    372\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 375\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    376\u001B[0m     is_inlier \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mones(X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m    377\u001B[0m     is_inlier[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecision_function(X) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    915\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    916\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    917\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    918\u001B[0m         )\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 921\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    929\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m~/PycharmProjects/fraud_detection_challenge/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    149\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m     )\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[0;31mValueError\u001B[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "''' submission data '''\n",
    "\n",
    "submission_user_data = {}\n",
    "session_classification = {}\n",
    "\n",
    "for user_id, user_data_path in tqdm.tqdm(zip(submission_user_list, submission_data_path), total=len(submission_user_list)):\n",
    "    #   load user data\n",
    "    submission_user_data[user_id] = User(user_id, user_data_path, gt_df[user_id])\n",
    "\n",
    "    # create segment features\n",
    "    submission_user_data[user_id].build_segment_features()\n",
    "\n",
    "    anomaly_ground_truth = submission_user_data[user_id].user_anomaly_gt.values.astype(int) # test set only\n",
    "    anomaly_ground_truth = np.array([1 if x == 0 else -1 for x in anomaly_ground_truth])\n",
    "\n",
    "    ''' high dim data '''\n",
    "\n",
    "    detector = DetectionPipeline()\n",
    "\n",
    "    detector.fit(submission_user_data[user_id].segment_df_train)\n",
    "    predicted_anomalies = detector.predict(submission_user_data[user_id].segment_df_test)\n",
    "    user_scores_high_dim[user_id] = detection_metrics(predicted_anomalies, anomaly_ground_truth)\n",
    "\n",
    "    session_classification[user_id] = [1 if x == -1 else 0 for x in predicted_anomalies]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T19:09:23.315448185Z",
     "start_time": "2023-05-21T19:09:21.283111807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' submission file '''\n",
    "submission_df = pd.read_csv(\"challengeToFill.csv\", index_col=0).T\n",
    "for user_id in submission_user_list:\n",
    "    submission_df[user_id].iloc[50:] = session_classification[user_id]\n",
    "\n",
    "submission_df = submission_df.T.astype(int)\n",
    "submission_df.to_csv(\"submissions/203763339_1.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T19:09:23.314664791Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import plotly.express as px\n",
    "#\n",
    "# viz_df_train = pd.DataFrame({\n",
    "#     \"x\": S_train_low_dim[:, 0],\n",
    "#     \"y\": S_train_low_dim[:, 1],\n",
    "#     \"user\": TRAIN_SEGMENT_COUNT * [user_id],\n",
    "#     \"set\": TRAIN_SEGMENT_COUNT * [\"train\"]\n",
    "# })\n",
    "#\n",
    "# viz_df_test = pd.DataFrame({\n",
    "#     \"x\": S_dev_low_dim[:, 0],\n",
    "#     \"y\": S_dev_low_dim[:, 1],\n",
    "#     \"user\": TEST_SEGMENT_COUNT * [user_id],\n",
    "#     \"set\": TEST_SEGMENT_COUNT * [\"test\"]\n",
    "# })\n",
    "#\n",
    "#\n",
    "# viz_df = pd.concat([viz_df_train, viz_df_test], axis=0)\n",
    "# viz_df[\"anomaly\"] = gt_df.T[user_id].values\n",
    "# viz_df[\"anomaly\"] = viz_df[\"anomaly\"].astype(int)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
